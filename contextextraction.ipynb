{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6e4986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dimtriospanagoulias/miniconda3/envs/LLMs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pypdf \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5b173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b08481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_pages(pdf_path:str):\n",
    "    pdf_reader = pypdf.PdfReader(pdf_path)\n",
    "    pages = [page.extract_text() for page in pdf_reader.pages]\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f8ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_sructured= \"1colExample.pdf\"\n",
    "pdf_unstructured= \"2colExample.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31147112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n"
     ]
    }
   ],
   "source": [
    "pagest_structured = extract_pdf_pages(pdf_sructured)\n",
    "pagest_unstructured = extract_pdf_pages(pdf_unstructured)\n",
    "print(len(pagest_structured), len(pagest_unstructured))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446131cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structured = pd.DataFrame({\n",
    "    \"page\":range(1, len(pagest_structured)+1),\n",
    "    \"text\": pagest_structured\n",
    "})\n",
    "\n",
    "df_unstructured = pd.DataFrame({\n",
    "    \"page\":range(1, len(pagest_unstructured)+1),\n",
    "    \"text\": pagest_unstructured\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38d16ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2 col example\\nIntroduction\\nBiomarker plays a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4. Biopsy if suspicious characteristics are ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>feature selection classification [12]. Feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The second and third steps are repeated until ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page                                               text\n",
       "0     1  2 col example\\nIntroduction\\nBiomarker plays a...\n",
       "1     2  4. Biopsy if suspicious characteristics are ob...\n",
       "2     3  feature selection classification [12]. Feature...\n",
       "3     4  The second and third steps are repeated until ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_structured.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4fa2628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(1 col example)\\nIntroduction\\nBiomarker plays...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the redundancy of data and increase the ac-\\nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>chine, it uses several support vector machines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page                                               text\n",
       "0     1  (1 col example)\\nIntroduction\\nBiomarker plays...\n",
       "1     2  the redundancy of data and increase the ac-\\nc...\n",
       "2     3  chine, it uses several support vector machines..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unstructured.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1375b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunks(text_list, model):\n",
    "    chunk_embeddings=model.encode(text_list, normalize_embeddings=True)\n",
    "    doc_embeddings = chunk_embeddings.mean(axis=0) # average doc-level\n",
    "    return chunk_embeddings, doc_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5c748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_struct_pages, emb_struct_doc = embed_chunks(pagest_structured, model)\n",
    "emb_unstruct_pages, emb_unstruct_doc = embed_chunks(pagest_unstructured, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8360b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structured[\"embedding\"] = [list(e) for e in emb_struct_pages]\n",
    "df_unstructured[\"embedding\"] = [list(e) for e in emb_unstruct_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4c277e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2 col example\\nIntroduction\\nBiomarker plays a...</td>\n",
       "      <td>[-0.016911913, 0.028695906, 0.0052786754, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4. Biopsy if suspicious characteristics are ob...</td>\n",
       "      <td>[0.012842059, 0.024613895, 0.010548779, -0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>feature selection classification [12]. Feature...</td>\n",
       "      <td>[-0.012905651, -0.00821479, -0.018207353, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The second and third steps are repeated until ...</td>\n",
       "      <td>[0.034310393, -0.02366298, 0.02857434, 0.01840...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page                                               text  \\\n",
       "0     1  2 col example\\nIntroduction\\nBiomarker plays a...   \n",
       "1     2  4. Biopsy if suspicious characteristics are ob...   \n",
       "2     3  feature selection classification [12]. Feature...   \n",
       "3     4  The second and third steps are repeated until ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.016911913, 0.028695906, 0.0052786754, -0.0...  \n",
       "1  [0.012842059, 0.024613895, 0.010548779, -0.013...  \n",
       "2  [-0.012905651, -0.00821479, -0.018207353, -0.0...  \n",
       "3  [0.034310393, -0.02366298, 0.02857434, 0.01840...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_structured.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbeb02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(1 col example)\\nIntroduction\\nBiomarker plays...</td>\n",
       "      <td>[-0.017610889, 0.0147622125, -0.007204978, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the redundancy of data and increase the ac-\\nc...</td>\n",
       "      <td>[-0.041768815, 0.0014158036, -0.024878249, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>chine, it uses several support vector machines...</td>\n",
       "      <td>[-0.12998605, -0.018148558, 0.0036243915, 0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page                                               text  \\\n",
       "0     1  (1 col example)\\nIntroduction\\nBiomarker plays...   \n",
       "1     2  the redundancy of data and increase the ac-\\nc...   \n",
       "2     3  chine, it uses several support vector machines...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.017610889, 0.0147622125, -0.007204978, -0....  \n",
       "1  [-0.041768815, 0.0014158036, -0.024878249, -0....  \n",
       "2  [-0.12998605, -0.018148558, 0.0036243915, 0.00...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unstructured.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96bbe5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unstructured_Page_1</th>\n",
       "      <th>Unstructured_Page_2</th>\n",
       "      <th>Unstructured_Page_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Structured_Page_1</th>\n",
       "      <td>0.920607</td>\n",
       "      <td>0.680938</td>\n",
       "      <td>0.397384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structured_Page_2</th>\n",
       "      <td>0.680696</td>\n",
       "      <td>0.744178</td>\n",
       "      <td>0.423352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structured_Page_3</th>\n",
       "      <td>0.665628</td>\n",
       "      <td>0.754512</td>\n",
       "      <td>0.572773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structured_Page_4</th>\n",
       "      <td>0.596418</td>\n",
       "      <td>0.611709</td>\n",
       "      <td>0.631951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Unstructured_Page_1  Unstructured_Page_2  \\\n",
       "Structured_Page_1             0.920607             0.680938   \n",
       "Structured_Page_2             0.680696             0.744178   \n",
       "Structured_Page_3             0.665628             0.754512   \n",
       "Structured_Page_4             0.596418             0.611709   \n",
       "\n",
       "                   Unstructured_Page_3  \n",
       "Structured_Page_1             0.397384  \n",
       "Structured_Page_2             0.423352  \n",
       "Structured_Page_3             0.572773  \n",
       "Structured_Page_4             0.631951  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare document embeddings\n",
    "sim_matrix = cosine_similarity(emb_struct_pages, emb_unstruct_pages)\n",
    "\n",
    "sim_differences = pd.DataFrame(\n",
    "    sim_matrix, \n",
    "    index=[f\"Structured_Page_{i+1}\" for i in range(len(pagest_structured))],\n",
    "    columns=[f\"Unstructured_Page_{i+1}\" for i in range(len(pagest_unstructured))]   \n",
    ")\n",
    "\n",
    "sim_differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498fedb1",
   "metadata": {},
   "source": [
    "# PDF Context Extraction and Embedding Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a complete pipeline for extracting text from PDF documents, generating semantic embeddings, and comparing document similarity. It processes both structured (single-column) and unstructured (multi-column) PDF layouts.\n",
    "\n",
    "## Components and Workflow\n",
    "\n",
    "### 1. Libraries and Dependencies\n",
    "- **pypdf**: PDF text extraction\n",
    "- **sentence_transformers**: Generate semantic embeddings using pre-trained models\n",
    "- **pandas**: Data organization and analysis\n",
    "- **sklearn**: Cosine similarity calculations\n",
    "\n",
    "### 2. Embedding Model\n",
    "Uses `all-MiniLM-L6-v2` model:\n",
    "- Lightweight transformer model (22M parameters)\n",
    "- Optimized for semantic similarity tasks\n",
    "- Generates 384-dimensional embeddings\n",
    "- Fast inference suitable for production use\n",
    "\n",
    "### 3. Key Functions\n",
    "\n",
    "#### `extract_pdf_pages(pdf_path)`\n",
    "- Extracts raw text from each PDF page\n",
    "- Returns list of page texts maintaining original order\n",
    "- Handles both single and multi-column layouts\n",
    "\n",
    "#### `embed_chunks(text_list, model)`\n",
    "- Generates embeddings for each text chunk (page)\n",
    "- Creates normalized embeddings for better similarity comparison\n",
    "- Computes document-level embedding by averaging page embeddings\n",
    "- Returns both page-level and document-level representations\n",
    "\n",
    "### 4. Processing Pipeline\n",
    "\n",
    "#### Step 1: PDF Extraction\n",
    "Extracts text from two example PDFs:\n",
    "- `1colExample.pdf`: Structured single-column layout\n",
    "- `2colExample.pdf`: Unstructured multi-column layout\n",
    "\n",
    "#### Step 2: Data Organization\n",
    "Creates DataFrames with:\n",
    "- Page numbers for reference\n",
    "- Extracted text content\n",
    "- Generated embeddings for each page\n",
    "\n",
    "#### Step 3: Embedding Generation\n",
    "- Each page gets a 384-dimensional vector representation\n",
    "- Embeddings capture semantic meaning of text\n",
    "- Normalized for consistent similarity scores\n",
    "\n",
    "#### Step 4: Similarity Analysis\n",
    "Computes cosine similarity matrix between:\n",
    "- All pages from structured PDF (rows)\n",
    "- All pages from unstructured PDF (columns)\n",
    "- Values range from -1 (opposite) to 1 (identical)\n",
    "\n",
    "## Results Interpretation\n",
    "\n",
    "### Similarity Matrix\n",
    "- **High values (>0.7)**: Strong semantic similarity between pages\n",
    "- **Medium values (0.3-0.7)**: Moderate topical overlap\n",
    "- **Low values (<0.3)**: Different topics or content\n",
    "\n",
    "### Use Cases\n",
    "1. **Content Deduplication**: Identify similar pages across documents\n",
    "2. **Document Clustering**: Group related pages/documents\n",
    "3. **Semantic Search**: Find relevant pages based on query\n",
    "4. **Information Retrieval**: Build knowledge bases with semantic indexing\n",
    "\n",
    "## Applications in RAG Systems\n",
    "This pipeline forms the foundation for:\n",
    "- **Document Chunking**: Splitting documents into semantic units\n",
    "- **Vector Databases**: Storing embeddings for fast retrieval\n",
    "- **Context Selection**: Finding relevant chunks for LLM prompts\n",
    "- **Quality Assessment**: Comparing extraction quality between formats\n",
    "\n",
    "## Performance Considerations\n",
    "- Page-level processing allows granular retrieval\n",
    "- Document-level embeddings enable fast initial filtering\n",
    "- Normalized embeddings ensure consistent similarity scores\n",
    "- Lightweight model balances speed and accuracy\n",
    "\n",
    "## Impact of Document Structure on Knowledge Extraction\n",
    "\n",
    "### Observed Similarity Patterns\n",
    "The similarity matrix reveals important insights about how document structure affects extraction quality:\n",
    "\n",
    "| Page Comparison | Similarity Score | Interpretation |\n",
    "|-----------------|------------------|----------------|\n",
    "| Struct_1 vs Unstruct_1 | 0.921 | Very high - likely same content |\n",
    "| Struct_1 vs Unstruct_2 | 0.681 | Moderate - partial content overlap |\n",
    "| Struct_1 vs Unstruct_3 | 0.397 | Low - different content sections |\n",
    "| Struct_2 vs Unstruct_2 | 0.744 | High - good content alignment |\n",
    "| Struct_3 vs Unstruct_2 | 0.755 | High - content properly matched |\n",
    "| Struct_4 vs Unstruct_3 | 0.632 | Moderate - partial alignment |\n",
    "\n",
    "### Key Issues with Multi-Column Extraction\n",
    "\n",
    "#### 1. **Content Fragmentation**\n",
    "- Multi-column PDFs often split related content across columns\n",
    "- PyPDF may read columns sequentially instead of logically\n",
    "- Results in broken sentences and disconnected paragraphs\n",
    "\n",
    "#### 2. **Misaligned Page Boundaries**\n",
    "- Structured PDF: Page 1 content â†’ High similarity (0.921) with Unstructured Page 1\n",
    "- But Structured Page 2-3 content appears split between Unstructured Pages 2-3\n",
    "- Indicates text reflow issues during extraction\n",
    "\n",
    "#### 3. **Semantic Coherence Loss**\n",
    "- Lower similarities for later pages (0.397-0.632) suggest:\n",
    "  - Context is being split unnaturally\n",
    "  - Related information ends up in different chunks\n",
    "  - Semantic meaning is diluted or lost\n",
    "\n",
    "### Downstream Impact on Knowledge Generation\n",
    "\n",
    "#### RAG System Implications:\n",
    "1. **Retrieval Accuracy**: Malformed chunks may not match relevant queries\n",
    "2. **Context Quality**: LLMs receive fragmented or incomplete context\n",
    "3. **Hallucination Risk**: Incomplete information increases generation errors\n",
    "4. **Answer Coherence**: Generated responses may miss critical connections\n",
    "\n",
    "#### Example Scenario:\n",
    "If a medical document discusses \"symptoms\" in one column and \"treatments\" in another:\n",
    "- **Proper extraction**: Single chunk contains complete symptom-treatment relationship\n",
    "- **Malformed extraction**: Symptoms and treatments in separate chunks\n",
    "- **Result**: LLM may generate incomplete or incorrect medical advice\n",
    "\n",
    "### Mitigation Strategies\n",
    "1. **Layout-Aware Extraction**: Use tools like `pdfplumber` or `pymupdf` with layout detection\n",
    "2. **Post-Processing**: Reconstruct logical reading order after extraction\n",
    "3. **Validation**: Compare embeddings to detect extraction anomalies\n",
    "4. **Chunk Overlap**: Use overlapping windows to preserve context\n",
    "5. **Manual Review**: Verify extraction quality for critical documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
